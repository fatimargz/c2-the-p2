{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a5ef22-e783-4110-b8a0-0aeaa426898d",
   "metadata": {},
   "source": [
    "# Awkward Array x NVIDIA\n",
    "Awkward Array provides an API to perform calculations using NVIDIA GPUs if available. This provides an interface familiar to Awkward users without needing any new knowledge of CUDA programming. Below, I will show how simple it is to leverage GPUs as accelerators with awkward.\n",
    "\n",
    "First, let's create an array of data on both the cpu and GPU by specifying the requested 'backend'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911d8b51-e9d9-4511-958d-f3f518c91508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "data = np.array([0,1,2,3,4,5,6,7,8,9,10])\n",
    "array_CPU = ak.Array(data, backend = \"cpu\")\n",
    "array_GPU = ak.Array(data, backend = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f841c80d-a80b-49bc-8114-8e2c0f411aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10]\n",
       "----------------\n",
       "backend: cuda\n",
       "nbytes: 88 B\n",
       "type: 11 * int64</pre>"
      ],
      "text/plain": [
       "<Array [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] type='11 * int64'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb288178-8c05-4951-9e5f-5587ce81b0d2",
   "metadata": {},
   "source": [
    "Let's compare the performance between the backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b367397-caef-482e-9f9f-773daf9781b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 μs ± 2.03 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# CPU\n",
    "array_CPU**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d83f7c-2397-4258-9509-bc34c13d9b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 ms ± 252 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# GPU\n",
    "array_GPU**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d124468-7da1-4a6f-9049-9adf674c6eb3",
   "metadata": {},
   "source": [
    "But wait! Here we see that using the GPU is a fair bit slower. GPUs have high throughput, but they also have high latency. It takes time for the CPU to send instructions to the GPU, and copying the result back to the host (CPU) is an expensive operation. GPUs realize performance benefits when the computation time far exceeds the latency overhead. Let's compare again but with much more data (~4GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2f1ee2-d988-4006-868c-08c0dfd7332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.int32\n",
    "shape = (500_000_000)\n",
    "data = np.random.default_rng().integers(low=0,high=10,size = shape)\n",
    "array_CPU = ak.Array(data, backend = \"cpu\")\n",
    "array_GPU = ak.Array(data, backend = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a5e380c-47fb-4e1c-bd5c-b4e01e4799de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " ...,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 8]\n",
       "-----------------------\n",
       "backend: cuda\n",
       "nbytes: 4.0 GB\n",
       "type: 500000000 * int64</pre>"
      ],
      "text/plain": [
       "<Array [6, 2, 3, 1, 6, 3, 1, ..., 2, 3, 2, 6, 1, 7, 8] type='500000000 * int64'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d175a060-1ac1-4b88-ae76-5f4bd5f8a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 505 ms, sys: 952 ms, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = array_CPU**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1827e2f4-7a4f-4f2b-84f6-3e828d940a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 ms, sys: 16.9 ms, total: 22.3 ms\n",
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = array_GPU**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a0262-680a-4272-b449-f59d5e6aaa90",
   "metadata": {},
   "source": [
    "# Cupy\n",
    "\n",
    "`Cupy` is a library which functions as an extension of `numpy` but for arrays stored on CUDA capable GPUs. Many of the numpy functions are implemented for `cupy`, and `cupy` provides an API which gives access to certain cuda functionalities (device synching, cuda streams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d577bb-b558-4b38-af46-efb24ce77890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "shape = (1000,1000)\n",
    "data = np.random.default_rng().integers(low=0,high=100,size = shape)\n",
    "data_cupy = cp.array(data)\n",
    "data_cpu = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64aa354b-2ec4-42ea-adb0-2a61b1aebbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupy.ndarray'>\n",
      "<MemoryPointer 0x7f8a92800000 device=0 mem=<cupy.cuda.memory.PooledMemory object at 0x7f92e9751fb0>>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_cupy))\n",
    "print(data_cupy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebcb6961-217d-4d11-ba63-33a7147e3eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = np.matmul(data_cpu, data_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f96da1d0-cd71-4db1-aa10-fa9a06b578b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 μs ± 62.8 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = cp.matmul(data_cupy, data_cupy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb1f8b-749f-4366-b6e8-75f743e43923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-kvikio-cuda12.5-py3.11]",
   "language": "python",
   "name": "conda-env-.conda-kvikio-cuda12.5-py3.11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
